{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up Colab environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "username = 'SkoltechAI'\n",
    "repo = 'Recommender-Systems-Intro-Sber-2022'\n",
    "\n",
    "# remove local directory if it already exists\n",
    "if os.path.isdir(repo):\n",
    "    !rm -rf {repo}\n",
    "\n",
    "!git clone https://github.com/{username}/{repo}.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --no-cache-dir --upgrade git+https://github.com/evfro/polara.git@develop#egg=polara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix, diags, csr_matrix\n",
    "from scipy.sparse.linalg import norm as spnorm\n",
    "\n",
    "from polara import get_movielens_data\n",
    "from polara.preprocessing.dataframes import leave_one_out, reindex\n",
    "\n",
    "# navigating to cloned repo directory in Colab\n",
    "%cd {repo} \n",
    "from dataprep import transform_indices\n",
    "from evaluation import topn_recommendations, model_evaluate, downvote_seen_items\n",
    "# restoring original location\n",
    "%cd - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepraring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_movielens_data(include_time=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_, holdout_ = leave_one_out(data, target='timestamp', sample_top=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered 2 invalid observations.\n"
     ]
    }
   ],
   "source": [
    "training, data_index = transform_indices(training_, 'userid', 'movieid')\n",
    "holdout = reindex(holdout_, data_index.values(), filter_invalid=True)\n",
    "holdout = holdout.sort_values('userid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'users': 'userid',\n",
       " 'items': 'movieid',\n",
       " 'feedback': 'rating',\n",
       " 'n_users': 6040,\n",
       " 'n_items': 3704,\n",
       " 'test_users': array([   0,    1,    2, ..., 6037, 6038, 6039], dtype=int64)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_description = dict(\n",
    "    users = data_index['users'].name,\n",
    "    items = data_index['items'].name,\n",
    "    feedback = 'rating',\n",
    "    n_users = len(data_index['users']),\n",
    "    n_items = len(data_index['items']),\n",
    "    test_users = holdout[data_index['users'].name].drop_duplicates().values\n",
    ")\n",
    "data_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "userid = data_description['users']\n",
    "seen_data = training.loc[lambda x: x[userid].isin(data_description[\"test_users\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-based KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(matrix):\n",
    "    row_norm = spnorm(matrix, axis=1).squeeze()\n",
    "    inv_norm = np.divide(1., row_norm, where=row_norm>0)\n",
    "    matrix_normed = diags(inv_norm).dot(matrix)\n",
    "    similarity = matrix_normed.dot(matrix_normed.T)\n",
    "    similarity.setdiag(0)\n",
    "    similarity.eliminate_zeros()\n",
    "    return similarity.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_naive_uknn_model(config, data, data_description):\n",
    "    # get indices of observed data\n",
    "    user_idx = data[data_description['users']].values\n",
    "    item_idx = data[data_description['items']].values\n",
    "    feedback = data[data_description['feedback']].values\n",
    "    # construct rating matrix\n",
    "    shape = (data_description['n_users'], data_description['n_items'])\n",
    "    user_item_mtx = coo_matrix((feedback, (user_idx, item_idx)), shape=shape)\n",
    "    # compute similarity matrix\n",
    "    user_similarity = cosine_similarity(user_item_mtx)\n",
    "    return user_item_mtx.tocsr(), user_similarity\n",
    "\n",
    "\n",
    "def naive_uknn_model_scoring(params, testset, testset_description, weighting_scheme=False):\n",
    "    user_item_mtx, user_similarity = params\n",
    "    test_users = testset_description['test_users']\n",
    "    # compute normalization coefficients and scores\n",
    "    if weighting_scheme is None: # scheme: KA / KB\n",
    "        ... # <- your code here\n",
    "    elif isinstance(weighting_scheme, str):\n",
    "        if weighting_scheme.startswith('col'): # column-wise scheme: KDA\n",
    "        ... # <- your code here\n",
    "        else: # ignore other shemes\n",
    "            raise ValueError('Unrecognized weighting scheme')\n",
    "    else:\n",
    "        raise ValueError('Unrecognized weighting scheme')\n",
    "    return scores.A # return dense scores array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "uknn_params = build_naive_uknn_model({}, training, data_description, elementwise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "uknn_scores = naive_uknn_model_scoring(uknn_params, None, data_description, elementwise=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "downvote_seen_items(uknn_scores, seen_data, data_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "uknn_recs = topn_recommendations(uknn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR=0.0502, MRR=0.0186, COV=0.0508\n"
     ]
    }
   ],
   "source": [
    "print('HR={:.3}, MRR={:.3}, COV={:.3}'.format(*model_evaluate(uknn_recs, holdout, data_description)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item-based KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_naive_iknn_model(config, data, data_description):\n",
    "    # get indices of observed data\n",
    "    user_idx = data[data_description['users']].values\n",
    "    item_idx = data[data_description['items']].values\n",
    "    relscore = data[data_description['feedback']].values\n",
    "    # construct rating matrix\n",
    "    shape = (data_description['n_users'], data_description['n_items'])\n",
    "    user_item_mtx = coo_matrix((relscore, (user_idx, item_idx)), shape=shape)\n",
    "    # compute similarity matrix and normalization coefficients\n",
    "    item_similarity_ = cosine_similarity(user_item_mtx.T)\n",
    "    item_similarity = truncate_similarity(item_similarity_, config['K'])\n",
    "    return user_item_mtx.tocsr(), item_similarity\n",
    "\n",
    "\n",
    "def truncate_similarity(similarity, k):\n",
    "    similarity = similarity.tocsr()\n",
    "    inds = similarity.indices\n",
    "    ptrs = similarity.indptr\n",
    "    data = similarity.data\n",
    "    new_ptrs = [0]\n",
    "    new_inds = []\n",
    "    new_data = []\n",
    "    for i in range(len(ptrs)-1):\n",
    "        start, stop = ptrs[i], ptrs[i+1]\n",
    "        if start < stop:\n",
    "            data_chunk = data[start:stop]\n",
    "            topk = min(len(data_chunk), k)\n",
    "            idx = np.argpartition(data_chunk, -topk)[-topk:]\n",
    "            new_data.append(data_chunk[idx])\n",
    "            new_inds.append(inds[idx+start])\n",
    "            new_ptrs.append(new_ptrs[-1]+len(idx))\n",
    "        else:\n",
    "            new_ptrs.append(new_ptrs[-1])\n",
    "    new_data = np.concatenate(new_data)\n",
    "    new_inds = np.concatenate(new_inds)\n",
    "    truncated = csr_matrix(\n",
    "        (new_data, new_inds, new_ptrs),\n",
    "        shape=similarity.shape\n",
    "    )\n",
    "    return truncated\n",
    "    \n",
    "\n",
    "def naive_iknn_model_scoring(params, testset, testset_description, weighting_scheme=None):\n",
    "    user_item_mtx, item_similarity = params\n",
    "    test_users = testset_description['test_users']\n",
    "    if weighting_scheme is None: # no weighting\n",
    "        scores = user_item_mtx[test_users].dot(item_similarity.T)\n",
    "    elif isinstance(weighting_scheme, str):\n",
    "        if weighting_scheme.startswith('el'):  # element-wise, ASt / BSt\n",
    "            scores_unweighted = user_item_mtx[test_users].dot(item_similarity.T)\n",
    "            weights_data = (user_item_mtx[test_users] != 0).dot(item_similarity.T)\n",
    "            weights_data.eliminate_zeros()\n",
    "            weights = weights_data._with_data(1. / weights_data.data)        \n",
    "            scores = scores_unweighted.multiply(weights)\n",
    "        elif weighting_scheme.startswith('row'):# row-wise, AStD\n",
    "            weights_data = item_similarity.sum(axis=1).A.squeeze()\n",
    "            weights = diags(np.divide(1., weights_data, where=weights_data!=0))\n",
    "            scores = user_item_mtx[test_users].dot(item_similarity.T.dot(weights))\n",
    "        elif weighting_scheme.startswith('col'): # column-wise, ADSt\n",
    "            weights_data = item_similarity.sum(axis=1).A.squeeze()\n",
    "            weights = diags(np.divide(1., weights_data, where=weights_data!=0))\n",
    "            scores = user_item_mtx[test_users].dot(weights.dot(item_similarity.T))\n",
    "        else:\n",
    "            raise ValueError('Unrecognized weighting scheme')\n",
    "    else:\n",
    "        raise ValueError('Unrecognized weighting scheme')\n",
    "    return scores.A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build item-KNN models with additional truncation of similarity weights to sparsify similarity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "iknn_params = build_naive_iknn_model({'K': 100}, training, data_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ewn_iknn_scores = naive_iknn_model_scoring(iknn_params, None, data_description, weighting_scheme='element')\n",
    "rwn_iknn_scores = naive_iknn_model_scoring(iknn_params, None, data_description, weighting_scheme='row')\n",
    "cwn_iknn_scores = naive_iknn_model_scoring(iknn_params, None, data_description, weighting_scheme='col')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "downvote_seen_items(ewn_iknn_scores, seen_data, data_description)\n",
    "downvote_seen_items(rwn_iknn_scores, seen_data, data_description)\n",
    "downvote_seen_items(cwn_iknn_scores, seen_data, data_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ewn_iknn_recs = topn_recommendations(ewn_iknn_scores)\n",
    "rwn_iknn_recs = topn_recommendations(rwn_iknn_scores)\n",
    "cwn_iknn_recs = topn_recommendations(cwn_iknn_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True elementwise normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR=0.001, MRR=0.000, COV=0.994\n"
     ]
    }
   ],
   "source": [
    "print('HR={:.3f}, MRR={:.3f}, COV={:.3f}'.format(*model_evaluate(ewn_iknn_recs, holdout, data_description)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse=1.214\n"
     ]
    }
   ],
   "source": [
    "predicted_rating = ewn_iknn_scores[np.arange(holdout.shape[0]), holdout['movieid'].values]\n",
    "rmse = np.mean(np.abs(predicted_rating-holdout['rating'].values)**2)\n",
    "print(f'RMSE={rmse:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Row-wise normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR=0.066, MRR=0.021, COV=0.568\n"
     ]
    }
   ],
   "source": [
    "print('HR={:.3f}, MRR={:.3f}, COV={:.3f}'.format(*model_evaluate(rwn_iknn_recs, holdout, data_description)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse=9.113\n"
     ]
    }
   ],
   "source": [
    "predicted_rating = rwn_iknn_scores[np.arange(holdout.shape[0]), holdout['movieid'].values]\n",
    "rmse = np.mean(np.abs(predicted_rating-holdout['rating'].values)**2)\n",
    "print(f'RMSE={rmse:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column-wise normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR=0.077, MRR=0.027, COV=0.437\n"
     ]
    }
   ],
   "source": [
    "print('HR={:.3f}, MRR={:.3f}, COV={:.3f}'.format(*model_evaluate(cwn_iknn_recs, holdout, data_description)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse=9.874\n"
     ]
    }
   ],
   "source": [
    "predicted_rating = cwn_iknn_scores[np.arange(holdout.shape[0]), holdout['movieid'].values]\n",
    "rmse = np.mean(np.abs(predicted_rating-holdout['rating'].values)**2)\n",
    "print(f'RMSE={rmse:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "iknn_scores = naive_iknn_model_scoring(iknn_params, None, data_description, weighting_scheme=None)\n",
    "downvote_seen_items(iknn_scores, seen_data, data_description)\n",
    "iknn_recs = topn_recommendations(iknn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR=0.076, MRR=0.027, COV=0.349\n"
     ]
    }
   ],
   "source": [
    "print('HR={:.3f}, MRR={:.3f}, COV={:.3f}'.format(*model_evaluate(iknn_recs, holdout, data_description)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse=1446.419\n"
     ]
    }
   ],
   "source": [
    "predicted_rating = iknn_scores[np.arange(holdout.shape[0]), holdout['movieid'].values]\n",
    "rmse = np.mean(np.abs(predicted_rating-holdout['rating'].values)**2)\n",
    "print(f'RMSE={rmse:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3afa3a53b6c5115441aadb460f6d4b1cc743652d4c25bab805986e920f52c789"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('sberrec')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
